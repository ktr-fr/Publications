@misc{t.ReponseVincentLacomme2024,
  title = {{R{\'e}ponse {\`a} Vincent Lacomme sur RAG vs LLM}},
  author = {T., Kikala},
  year = {2024},
  month = sep,
  abstract = {Correspondance avec Vincent LACOMME du 2024-09-09 Objet : Vincent me demande mon avis d'expert sur l'opposition entre le RAG et les LLMs (avec contexte long) dans cette {\'e}tude technique In Defense of RAG in the Era of Long-Context Language Models https://arxiv.org/abs/2409.01666 R{\'e}ponse : Pour cr{\'e}er une analogie avec un organisme vivant pour cet abstract d'IA, nous pouvons comparer le syst{\`e}me d'IA au cerveau humain et {\`a} son interaction avec l'environnement : Le cerveau humain (que nous comparons au LLM) existe dans un environnement complexe (donn{\'e}es/contexte) et doit traiter l'information pour g{\'e}n{\'e}rer des r{\'e}ponses. {\`A} mesure que le cerveau {\'e}volue (comme les nouvelles g{\'e}n{\'e}rations de LLM), il d{\'e}veloppe des capacit{\'e}s am{\'e}lior{\'e}es pour g{\'e}rer de plus grandes quantit{\'e}s d'informations. L'{\'e}volution du traitement de l'information Cerveau au stade pr{\'e}coce (premiers LLM avec RAG) : {\`A} ses d{\'e}buts, le cerveau a une capacit{\'e} limit{\'e}e {\`a} traiter de grandes quantit{\'e}s d'informations {\`a} la fois. Pour compenser, il d{\'e}veloppe un syst{\`e}me similaire au RAG : 	0.	Il r{\'e}cup{\`e}re s{\'e}lectivement les souvenirs ou les connaissances pertinents (r{\'e}cup{\'e}ration) 	0.	Utilise ces informations r{\'e}cup{\'e}r{\'e}es pour former des pens{\'e}es ou des r{\'e}ponses (g{\'e}n{\'e}ration) Ce processus est comparable {\`a} un enfant qui doit consciemment se rappeler des faits sp{\'e}cifiques pour r{\'e}pondre {\`a} des questions, plut{\^o}t que d'avoir une compr{\'e}hension holistique (c'est {\`a} dire du tout) Cerveau avanc{\'e} (LLM {\`a} contexte long) : {\`A} mesure que le cerveau m{\^u}rit, il d{\'e}veloppe la capacit{\'e} de retenir et de traiter beaucoup plus d'informations simultan{\'e}ment. C'est analogue aux LLM {\`a} contexte long qui peuvent absorber de vastes quantit{\'e}s de donn{\'e}es en une seule fois. Le d{\'e}fi de la surcharge d'information Cependant, tout comme le cerveau humain peut {\^e}tre submerg{\'e} par trop de stimuli, les LLM {\`a} contexte long peuvent avoir du mal {\`a} se concentrer sur les informations les plus pertinentes lorsqu'ils re{\c c}oivent des entr{\'e}es extr{\^e}mement volumineuses. Cela peut entra{\^i}ner une baisse de la qualit{\'e} des r{\'e}ponses, similaire {\`a} la fa{\c c}on dont une personne pourrait avoir du mal {\`a} se concentrer dans un environnement tr{\`e}s bruyant ou chaotique. OP-RAG : Une approche {\'e}quilibr{\'e}e Le m{\'e}canisme OP-RAG propos{\'e} est comme entra{\^i}ner le cerveau {\`a} utiliser une m{\'e}thode plus raffin{\'e}e de collecte et de traitement de l'information : 	1.	Il r{\'e}cup{\`e}re s{\'e}lectivement l'information (comme une attention focalis{\'e}e) 	2.	Maintient l'ordre et le contexte originaux de l'information (pr{\'e}servant les relations entre les id{\'e}es) 	3.	Trouve une quantit{\'e} optimale d'informations {\`a} traiter ({\'e}vitant la surcharge) Cette approche imite la fa{\c c}on dont un expert pourrait aborder un probl{\`e}me complexe - rassembler suffisamment d'informations pertinentes pour former une compr{\'e}hension globale La "courbe en U invers{\'e}" de la performance ressemble {\`a} la fa{\c c}on dont la performance cognitive humaine atteint souvent un pic avec un niveau optimal de stimulation ou de d{\'e}fi, d{\'e}clinant lorsqu'il y a trop peu ou trop d'informations {\`a} traiter efficacement. En trouvant ce point optimal, OP-RAG permet au "cerveau" de l'IA de g{\'e}n{\'e}rer des r{\'e}ponses de haute qualit{\'e} tout en traitant moins d'informations que s'il essayait d'absorber tout l'"environnement" d'un coup, tout comme les humains performent souvent mieux en se concentrant sur les d{\'e}tails pertinents plut{\^o}t qu'en essayant de traiter chaque {\'e}l{\'e}ment d'information disponible simultan{\'e}ment.},
  langid = {french},
  keywords = {GenAI},
  note = {\href{https://arxiv.org/abs/2409.01666}{https://arxiv.org/abs/2409.01666}},
  file = {files/5/T. - 2024 - Réponse à Vincent Lacomme sur RAG vs LLM.m4a}
}
